{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "47de2fa8-fca1-4d49-aa14-2fbc9610449b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "14bdb1c2-8dc4-4d61-a5d4-f4369152b011",
   "metadata": {},
   "outputs": [],
   "source": [
    "MIN_SPLIT = 10\n",
    "MIN_SAMPLES_LEAF = 5\n",
    "MAX_HEIGHT = 5\n",
    "CONTINUOUS = \"CO\"\n",
    "CATEGORICAL = \"CA\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7720ceb3-4f77-476e-8767-53b199f0bf94",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sorts a matrix by a given column\n",
    "def sort_by_column(matrix,sort_coordinate):\n",
    "    new_order = matrix[:,sort_coordinate].argsort()\n",
    "    out = matrix.copy()[new_order]\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8bd92973-0ec7-4e9f-8d51-33f0a2f000c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Node:\n",
    "    def __init__(self,val,column,function,prediction=None):\n",
    "        self.val = val\n",
    "        self.function = function #recieves two numbers and returns either True or False, True go left, False go right\n",
    "        self.column = column\n",
    "        self.left = None\n",
    "        self.right = None\n",
    "        self.prediction = prediction #Mean of all samples that pass trough node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b46e0f98-4e30-490e-82d9-b8697a331f87",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecisionTreeRegressor:\n",
    "    def __init__(self,error = \"se\",max_height = MAX_HEIGHT,min_samples_leaf = MIN_SAMPLES_LEAF,min_split = MIN_SPLIT):\n",
    "        self.head = None\n",
    "        self.error_metric = self.__return_error_metric(error)\n",
    "        self.max_height = max_height\n",
    "        self.min_samples_leaf = min_samples_leaf\n",
    "        self.min_split = min_split\n",
    "\n",
    "    def __is_smaller(self,a,b):\n",
    "        return a<b\n",
    "\n",
    "    def __is_equal(self,a,b):\n",
    "        return a==b\n",
    "\n",
    "    def __measure_array_se(self,arr):\n",
    "        return sum((arr-np.mean(arr))**2)\n",
    "\n",
    "    def __measure_array_ae(self,arr):\n",
    "        return sum(np.abs(arr-np.mean(arr)))\n",
    "\n",
    "    def __return_error_metric(self,error):\n",
    "        if error == 'ae':\n",
    "            return self.__measure_array_ae\n",
    "        else:\n",
    "            return self.__measure_array_se\n",
    "        \n",
    "    def __find_continuous_column_best_split(self,data,column):\n",
    "        data = sort_by_column(data,column)\n",
    "        \n",
    "        column_data = data[:,column]\n",
    "        \n",
    "        best_error = np.inf\n",
    "\n",
    "        best_split_val = None\n",
    "        \n",
    "        best_left,best_right = None,None\n",
    "\n",
    "        last_val = column_data[0]\n",
    "            \n",
    "        for i in range(self.min_samples_leaf,len(column_data)-self.min_samples_leaf):\n",
    "            if column_data[i] == last_val:\n",
    "                continue\n",
    "\n",
    "            last_val = column_data[i]\n",
    "\n",
    "            split_val = (column_data[i] + column_data[i-1])/2\n",
    "            \n",
    "            left_arr = data[:i , :]\n",
    "            right_arr = data[i: , :]\n",
    "            \n",
    "            split_error = self.error_metric(left_arr[:,-1]) + self.error_metric(right_arr[:,-1]) \n",
    "\n",
    "            \n",
    "            if split_error < best_error:\n",
    "                \n",
    "                best_error =  split_error\n",
    "                best_split_val = split_val\n",
    "                best_left = left_arr\n",
    "                best_right = right_arr\n",
    "                \n",
    "        \n",
    "        return best_split_val,best_error,best_left,best_right\n",
    "    \n",
    "    def __find_categorical_column_best_split(self,data,column):    \n",
    "        column_data = data[:,column]\n",
    "    \n",
    "        classes = np.unique(column_data)\n",
    "        \n",
    "        best_error = np.inf\n",
    "        \n",
    "        best_split_val = None\n",
    "        \n",
    "        best_left,best_right = None,None\n",
    "            \n",
    "        for c in classes:\n",
    "            left_arr = data[column_data == c]\n",
    "            right_arr = data[column_data != c]\n",
    "    \n",
    "            if len(left_arr) < self.min_samples_leaf or len(right_arr) < self.min_samples_leaf:\n",
    "                continue\n",
    "            \n",
    "            split_error = self.error_metric(left_arr[:,-1]) + self.error_metric(right_arr[:,-1]) \n",
    "            if split_error < best_error:\n",
    "                \n",
    "                best_error =  split_error\n",
    "                best_split_val = c\n",
    "                best_left = left_arr\n",
    "                best_right = right_arr\n",
    "                \n",
    "        \n",
    "        return best_split_val,best_error,best_left,best_right\n",
    "    \n",
    "    def __find_column_best_split(self,data,column,data_type):\n",
    "        if data_type == CATEGORICAL:\n",
    "            return self.__find_categorical_column_best_split(data,column)\n",
    "        if data_type == CONTINUOUS:\n",
    "            return self.__find_continuous_column_best_split(data,column)\n",
    "\n",
    "    def __find_best_split(self,data,data_types):\n",
    "        best_column = -1\n",
    "        best_val = data[0][0]\n",
    "        best_mse = np.inf\n",
    "        best_left = None\n",
    "        best_right = None\n",
    "        for col in range(len(data[0])-1): #Iterate over all columns but the last one which is the label\n",
    "            col_best_split_val,col_best_mse,col_best_left,col_best_right = self.__find_column_best_split(data,col,data_types[col])\n",
    "            if col_best_mse < best_mse:\n",
    "                best_val,best_mse,best_left,best_right = col_best_split_val,col_best_mse,col_best_left,col_best_right\n",
    "                best_column = col\n",
    "        return best_column,best_val,best_left,best_right\n",
    "    \n",
    "    def __build_tree(self,data,data_types,height=0):\n",
    "        if (height >= self.max_height) or (len(data) <= self.min_split):\n",
    "            return None\n",
    "        best_column,best_val,left_data,right_data = self.__find_best_split(data,data_types)\n",
    "        if left_data is None:\n",
    "            return None\n",
    "        function = self.__is_smaller if data_types[best_column] == CONTINUOUS else self.__is_equal\n",
    "        node = Node(val=best_val,column=best_column,function=function,prediction=np.mean(data[:,-1]))\n",
    "        node.left = self.__build_tree(left_data,data_types,height+1)\n",
    "        node.right = self.__build_tree(right_data,data_types,height+1)\n",
    "        return node\n",
    "    \n",
    "    def fit(self,X,y,data_types):\n",
    "        H = np.hstack([X,y.reshape(len(y),1)]).copy()\n",
    "        self.head = self.__build_tree(H,data_types)\n",
    "\n",
    "    def __predict_point(self,x):\n",
    "        prev = None\n",
    "        curr = self.head\n",
    "        while curr is not None:\n",
    "            col_to_check = curr.column\n",
    "            val = curr.val\n",
    "            function = curr.function\n",
    "            prev = curr\n",
    "            if function(x[col_to_check] , val):\n",
    "                curr = curr.left\n",
    "            else:\n",
    "                curr = curr.right\n",
    "        return prev.prediction\n",
    "\n",
    "    def predict(self,X):\n",
    "        out = []\n",
    "        for x in X:\n",
    "            out.append(self.__predict_point(x))\n",
    "        return np.array(out)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bee6bc7-388a-4fa4-a688-da20deb913d1",
   "metadata": {},
   "source": [
    "<h3>Using our model and comparing it to Sklearn's DecisionTreeRegressor</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "40f41751-37cd-48ed-bc61-648b0d9a1cf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "#Using only a few columns for testing\n",
    "train_data = pd.read_csv('train.csv')[['LotFrontage','Street','LotShape','Utilities','YrSold','1stFlrSF','SalePrice']].dropna() "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63997092-b8a8-4eb4-8d62-b6cc38c7258e",
   "metadata": {},
   "source": [
    "<h5>Some sample data for the sale price of a house (from kaggle getting started datasets)</h5>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6a20879a-d2db-4d6e-8207-bdbb2059100e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LotFrontage</th>\n",
       "      <th>Street</th>\n",
       "      <th>LotShape</th>\n",
       "      <th>Utilities</th>\n",
       "      <th>YrSold</th>\n",
       "      <th>1stFlrSF</th>\n",
       "      <th>SalePrice</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>65.0</td>\n",
       "      <td>Pave</td>\n",
       "      <td>Reg</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>2008</td>\n",
       "      <td>856</td>\n",
       "      <td>208500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>80.0</td>\n",
       "      <td>Pave</td>\n",
       "      <td>Reg</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>2007</td>\n",
       "      <td>1262</td>\n",
       "      <td>181500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>68.0</td>\n",
       "      <td>Pave</td>\n",
       "      <td>IR1</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>2008</td>\n",
       "      <td>920</td>\n",
       "      <td>223500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>60.0</td>\n",
       "      <td>Pave</td>\n",
       "      <td>IR1</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>2006</td>\n",
       "      <td>961</td>\n",
       "      <td>140000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>84.0</td>\n",
       "      <td>Pave</td>\n",
       "      <td>IR1</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>2008</td>\n",
       "      <td>1145</td>\n",
       "      <td>250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1455</th>\n",
       "      <td>62.0</td>\n",
       "      <td>Pave</td>\n",
       "      <td>Reg</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>2007</td>\n",
       "      <td>953</td>\n",
       "      <td>175000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1456</th>\n",
       "      <td>85.0</td>\n",
       "      <td>Pave</td>\n",
       "      <td>Reg</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>2010</td>\n",
       "      <td>2073</td>\n",
       "      <td>210000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1457</th>\n",
       "      <td>66.0</td>\n",
       "      <td>Pave</td>\n",
       "      <td>Reg</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>2010</td>\n",
       "      <td>1188</td>\n",
       "      <td>266500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1458</th>\n",
       "      <td>68.0</td>\n",
       "      <td>Pave</td>\n",
       "      <td>Reg</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>2010</td>\n",
       "      <td>1078</td>\n",
       "      <td>142125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1459</th>\n",
       "      <td>75.0</td>\n",
       "      <td>Pave</td>\n",
       "      <td>Reg</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>2008</td>\n",
       "      <td>1256</td>\n",
       "      <td>147500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1201 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      LotFrontage Street LotShape Utilities  YrSold  1stFlrSF  SalePrice\n",
       "0            65.0   Pave      Reg    AllPub    2008       856     208500\n",
       "1            80.0   Pave      Reg    AllPub    2007      1262     181500\n",
       "2            68.0   Pave      IR1    AllPub    2008       920     223500\n",
       "3            60.0   Pave      IR1    AllPub    2006       961     140000\n",
       "4            84.0   Pave      IR1    AllPub    2008      1145     250000\n",
       "...           ...    ...      ...       ...     ...       ...        ...\n",
       "1455         62.0   Pave      Reg    AllPub    2007       953     175000\n",
       "1456         85.0   Pave      Reg    AllPub    2010      2073     210000\n",
       "1457         66.0   Pave      Reg    AllPub    2010      1188     266500\n",
       "1458         68.0   Pave      Reg    AllPub    2010      1078     142125\n",
       "1459         75.0   Pave      Reg    AllPub    2008      1256     147500\n",
       "\n",
       "[1201 rows x 7 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "91c57777-c657-4de2-bbb4-5e5535ec81d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_types = [CONTINUOUS,CATEGORICAL,CATEGORICAL,CATEGORICAL,CONTINUOUS,CONTINUOUS]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "72a924a6-b10d-4c7e-8448-b990bee754a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train_data.values[:,:-1]\n",
    "y = train_data.values[:,-1]\n",
    "test_size = int(len(X)/5)\n",
    "X_train, X_test, y_train, y_test = X[:-test_size],X[-test_size:],y[:-test_size],y[-test_size:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dc223350-6482-4d68-b657-ecacf7b96126",
   "metadata": {},
   "outputs": [],
   "source": [
    "DT = DecisionTreeRegressor()\n",
    "DT.fit(X_train,y_train,data_types)\n",
    "my_pred = DT.predict(X_test) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1f6cf97a-00e2-4803-b555-ffa0d4f96811",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# def printTree(node, level=0):\n",
    "#     if node != None:\n",
    "#         printTree(node.left, level + 1)\n",
    "#         print(' ' * 4 * level + '-> ' + str(node.prediction))\n",
    "#         printTree(node.right, level + 1)\n",
    "# printTree(DT.head)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2804b60-dc91-426a-91b1-7779fd0ce217",
   "metadata": {},
   "source": [
    "<h3>Now lets try with Sklearn</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69991025-d863-485b-b45d-23b8542fa512",
   "metadata": {},
   "source": [
    "<h3>Turning categorical columns to one-hot encoding so that Sklearn's decision tree can accept it</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b206f56d-cd30-4f4d-9db8-b5aa735ed06d",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('future.no_silent_downcasting', True)\n",
    "sklearn_train_data = train_data.copy()\n",
    "categorical_columns = ['Street','LotShape','Utilities']\n",
    "for col in categorical_columns:\n",
    "    train_temp = pd.get_dummies(sklearn_train_data[col]).replace({True:1,False:0})\n",
    "    train_temp.columns = [col + \"_\" +str(i) for i in range(len(train_temp.columns))]\n",
    "    sklearn_train_data = pd.concat([sklearn_train_data,train_temp],axis=1)\n",
    "    sklearn_train_data.drop(col,axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "21a9df10-a5f7-46ba-9552-d2e7399b343b",
   "metadata": {},
   "outputs": [],
   "source": [
    "sk_X = sklearn_train_data.drop('SalePrice',axis = 1).values\n",
    "sk_X_train, sk_X_test, y_train, y_test = sk_X[:-test_size],sk_X[-test_size:],y[:-test_size],y[-test_size:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "56cca6e3-74c6-4509-bbbf-4329cf4726c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor as DTR\n",
    "DTR = DTR(max_depth=MAX_HEIGHT,min_samples_leaf=MIN_SAMPLES_LEAF,min_samples_split=MIN_SPLIT)\n",
    "DTR.fit(sk_X_train,y_train)\n",
    "sklearn_pred = DTR.predict(sk_X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e711ff00-0908-4e00-8c14-cbc252a78c33",
   "metadata": {},
   "source": [
    "<h3>Now lets compare the performance</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8968d758-f67c-4441-bc61-2b19d9bef4ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mse(a,b):\n",
    "    return np.sqrt(sum((a-b)**2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3c2bd038-d3ce-4f0e-bb6b-2564da4f0574",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sklearn's tree performance :  100.21191991740572\n",
      "Our tree's performance :  98.4245019138269\n"
     ]
    }
   ],
   "source": [
    "print(\"Sklearn's tree performance : \" , mse(sklearn_pred,y_test)/10000)\n",
    "print(\"Our tree's performance : \" , mse(my_pred,y_test)/10000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7d3e859-a49f-4251-b1c2-1f2619b32a3d",
   "metadata": {},
   "source": [
    "<h3>We WIN!......but I guess that with some finetunning of the parameters we can get Sklearn's tree to match our's or even surpass it </h3>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
